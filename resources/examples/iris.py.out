Python 3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) 

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.0.0
      /_/

Using Python version 3.6.8 (default, Dec 29 2018 19:04:46)
SparkSession available as 'spark'.
Scavenger APIs (version 0.1.0-spark3.0-EXPERIMENTAL) available as 'scavenger'.
>>> # Loads a target data then defines tables for it
... iris_schema = "tid string, sepal_length double, sepal_width double, petal_length double, petal_width double"
>>> spark.read \
...   .option("header", True) \
...   .schema(iris_schema) \
...   .csv("./testdata/iris.csv") \
...   .write \
...   .saveAsTable("iris")
>>> 
>>> scavenger.repair().misc() \
...   .setDbName("default") \
...   .setTableName("iris") \
...   .setRowId("tid") \
...   .flatten() \
...   .write \
...   .saveAsTable("iris_flatten")
>>> 
>>> spark.table("iris").show(1)
+---+------------+-----------+------------+-----------+
|tid|sepal_length|sepal_width|petal_length|petal_width|
+---+------------+-----------+------------+-----------+
|  0|         5.1|        3.5|         1.4|        0.2|
+---+------------+-----------+------------+-----------+
only showing top 1 row

>>> spark.table("iris_flatten").show(1)
+---+------------+-----+
|tid|   attribute|value|
+---+------------+-----+
|  0|sepal_length|  5.1|
+---+------------+-----+
only showing top 1 row

>>> 
>>> # Loads a ground truth data then defines tables for it
... spark.read \
...   .option("header", True) \
...   .csv("./testdata/iris_clean.csv") \
...   .write \
...   .saveAsTable("iris_clean")
>>> 
>>> spark.table("iris_flatten") \
...   .join(spark.table("iris_clean"), ["tid", "attribute"], "inner") \
...   .where("not(value <=> correct_val)") \
...   .write \
...   .saveAsTable("error_cells_ground_truth")
>>> 
>>> spark.table("iris_clean").show(1)
+---+------------+-----------+
|tid|   attribute|correct_val|
+---+------------+-----------+
|  0|sepal_length|        5.1|
+---+------------+-----------+
only showing top 1 row

>>> spark.table("error_cells_ground_truth").show(1)
+---+-----------+-----+-----------+
|tid|  attribute|value|correct_val|
+---+-----------+-----+-----------+
|  7|sepal_width| null|        3.4|
+---+-----------+-----+-----------+
only showing top 1 row

>>> 
>>> # Detects error cells then repairs them
... val repaired_df = scavenger.repair() \
...   .setDbName("default") \
...   .setTableName("iris") \
...   .setRowId("tid") \
...   .run()
>>> 
>>> # Computes performance numbers for continous attributes (RMSE)
... n = spark.table("iris_repaired").count()
>>> rmse = repaired_df \
...   .join(spark.table("iris_clean"), ["tid", "attribute"], "inner") \
...   .selectExpr(f"sqrt(sum(pow(correct_val - repaired, 2.0)) / {n}) rmse") \
...   .collect()[0] \
...   .rmse
>>> 
>>> print(f"RMSE={rmse}")
RMSE=0.4064564495531232

